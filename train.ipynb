{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenizer와 model을 준비\n",
    "\n",
    "codet5가 코드 생성에 더 유리할 것으로 판단되지만 논문에서는 gptneo를 사용했으므로 해당 방식으로 일단 진행\n",
    "\n",
    "이에 따라 tokenizer를 따로 준비할 필요가 있어 get_gpt()함수를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from typing import Tuple, Optional, List, Union\n",
    "\n",
    "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
    "from transformers import PreTrainedModel, PreTrainedTokenizer, GPT2LMHeadModel\n",
    "from transformers import GPT2Tokenizer, GPTJForCausalLM\n",
    "\n",
    "def get_gpt(model_name: str, \n",
    "            tokenizer_only: bool = False,\n",
    "            gradient_ckpt: bool = False,\n",
    "            additional_special_tokens: Optional[List[str]] = None) \\\n",
    "        -> Tuple[PreTrainedModel, PreTrainedTokenizer]:\n",
    "    if additional_special_tokens is None:\n",
    "        additional_special_tokens = []\n",
    "\n",
    "    if not tokenizer_only:\n",
    "        print(f\"using pretrained model: {model_name}, gradient_ckpt: {gradient_ckpt}\")\n",
    "\n",
    "    if model_name == \"microsoft/CodeGPT-small-py\":\n",
    "        tokenizer = GPT2Tokenizer.from_pretrained(model_name, additional_special_tokens=additional_special_tokens)\n",
    "        if not tokenizer_only:\n",
    "            model = GPT2LMHeadModel.from_pretrained(model_name, pad_token_id=tokenizer.eos_token_id)\n",
    "            if len(additional_special_tokens) > 0:\n",
    "                model.resize_token_embeddings(len(tokenizer))\n",
    "    if model_name == \"EleutherAI/gpt-j-6B\":\n",
    "        tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "        if not tokenizer_only:\n",
    "            model = GPTJForCausalLM.from_pretrained(model_name, pad_token_id=tokenizer.eos_token_id,\n",
    "                                                        gradient_checkpointing=gradient_ckpt, use_cache=not gradient_ckpt)\n",
    "            if len(additional_special_tokens) > 0:\n",
    "                model.resize_token_embeddings(len(tokenizer))\n",
    "    elif model_name in [\"EleutherAI/gpt-neo-1.3B\", \"EleutherAI/gpt-neo-125M\", \"EleutherAI/gpt-neo-2.7B\"]:\n",
    "        tokenizer = GPT2Tokenizer.from_pretrained(model_name, additional_special_tokens=additional_special_tokens)\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "        if not tokenizer_only: \n",
    "            model = GPTNeoForCausalLM.from_pretrained(model_name, pad_token_id=tokenizer.eos_token_id, \n",
    "                                                    gradient_checkpointing=gradient_ckpt, use_cache=not gradient_ckpt)\n",
    "            if len(additional_special_tokens) > 0:\n",
    "                model.resize_token_embeddings(len(tokenizer))\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    if tokenizer_only:\n",
    "        return None, tokenizer\n",
    "    else:\n",
    "        return model, tokenizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델과 tokenizer가 준비되었으므로 dataset이 필요\n",
    "- HumanEval을 기준으로 코드 작업 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class HumanevalDatasets(torch.utils.data.Dataset):\n",
    "    def __init__(self, raw_data):\n",
    "        super().__init__()\n",
    "        self.raw_data = raw_data\n",
    "    def __len__(self):\n",
    "        return self.raw_data.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.raw_data[idx]\n",
    "        name = row['task_id']\n",
    "        label = row['canonical_solution']['solution']\n",
    "        input_description = row['prompt']\n",
    "        entry_point = row['entry_point']\n",
    "        test = row['test'][row['test'].find(':\\n'):].replace('candidate', entry_point).strip().split('\\n')\n",
    "        return (input_description, label, name, entry_point, test)     "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이후에는 모델을 학습시키는 코드 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/root/eunki/baseline/train.ipynb 셀 7\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsnu_13/root/eunki/baseline/train.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatetime\u001b[39;00m \u001b[39mimport\u001b[39;00m datetime\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsnu_13/root/eunki/baseline/train.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39margparse\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bsnu_13/root/eunki/baseline/train.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mappend(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mabspath(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(\u001b[39m__file__\u001b[39;49m))))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsnu_13/root/eunki/baseline/train.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimization\u001b[39;00m \u001b[39mimport\u001b[39;00m AdamW, get_cosine_schedule_with_warmup\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsnu_13/root/eunki/baseline/train.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmisc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mevaluate_metric\u001b[39;00m \u001b[39mimport\u001b[39;00m evaluate_metric\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import csv\n",
    "import os, sys\n",
    "from os.path import join, abspath, dirname\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(__file__))))\n",
    "\n",
    "from transformers.optimization import AdamW, get_cosine_schedule_with_warmup\n",
    "from misc.evaluate_metric import evaluate_metric\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from misc.colors import Colors\n",
    "\n",
    "global_rank = int(os.getenv('RANK', '0'))\n",
    "local_rank = int(os.getenv('LOCAL_RANK', '0'))\n",
    "world_size = int(os.getenv('WORLD_SIZE', '1'))\n",
    "\n",
    "def log(string):\n",
    "    if global_rank == 0:\n",
    "        print(string, flush=True)\n",
    "\n",
    "\n",
    "def set_seed(args):\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.n_gpu > 0:\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "\n",
    "def str2bool(v):\n",
    "    if isinstance(v, bool):\n",
    "        return v\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')\n",
    "\n",
    "class Trainer(object):\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        if world_size > 1:\n",
    "            self.device = f'cuda:{self.args.local_rank}'\n",
    "        elif world_size == 1:\n",
    "            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        self.model, self.tokenizer = get_gpt('EleutherAI/gpt-neo-125M')\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        if args.eval_only == True:\n",
    "            self.train_set = None\n",
    "        else:\n",
    "            self.train_set = HumanevalDatasets()\n",
    "        self.test_set = HumanevalDatasets()\n",
    "\n",
    "        os.makedirs(self.get_save_path(), exist_ok=True)\n",
    "\n",
    "        if self.args.eval_only == False:\n",
    "            self.train_loader = DataLoader(self.train_set, batch_size=self.args.train_batch_size, shuffle=True, drop_last=True)\n",
    "        elif self.args.eval_only == True:\n",
    "            self.train_loader = None\n",
    "        self.test_loader = DataLoader(self.test_set, batch_size=self.args.test_batch_size)\n",
    "\n",
    "    def evaluate(self, epoch_idx=0):\n",
    "        self.model.eval()\n",
    "\n",
    "        loader = self.test_loader\n",
    "\n",
    "        eval_b_cnt=0\n",
    "        eval_loss=0\n",
    "        with torch.no_grad():\n",
    "            log(f\"### START TEST ###\")\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            predictions = []\n",
    "            references = []\n",
    "            names = []\n",
    "            tests = []\n",
    "            entry_points = []\n",
    "            for i, (contexts, labels, name, entry_point, test) in enumerate(tqdm(loader, bar_format='{l_bar}{bar:10}{r_bar}')):\n",
    "                predictions += self.model.generate(contexts, labels)\n",
    "                references += labels\n",
    "                names += name\n",
    "                entry_points += entry_point\n",
    "                tests.append(test)\n",
    "\n",
    "                _loss,_ = self.model(contexts, labels)\n",
    "                eval_b_cnt+=1\n",
    "                eval_loss += _loss.item()\n",
    "\n",
    "            eval_loss = eval_loss/eval_b_cnt\n",
    "            perplexity = torch.exp(torch.tensor(eval_loss))\n",
    "\n",
    "            log(f\"{Colors.VIOLET}Test Epoch: {epoch_idx} Loss: {eval_loss} perplexity: {perplexity}{Colors.ENDC}\\n\")\n",
    "\n",
    "            # Metric\n",
    "            score = evaluate_metric(predictions, tests, self.args.dataset_type)\n",
    "        if self.args.save_test_inference != None and global_rank == 0:\n",
    "            with open(self.args.save_test_inference, 'a') as f:\n",
    "                wr = csv.writer(f, delimiter=\"\\t\")\n",
    "                for idx in range(len(references)):\n",
    "                    wr.writerow([epoch_idx, names[idx], references[idx], predictions[idx], score[idx]])\n",
    "\n",
    "        return eval_loss, perplexity\n",
    "\n",
    "    def get_task_name(self):\n",
    "        names = [self.args.model_name,\n",
    "                self.args.downstream_task,\n",
    "                self.args.mode,\n",
    "                self.args.dataset_type]\n",
    "        return \"_\".join(names)\n",
    "\n",
    "    def get_save_path(self):\n",
    "        if self.args.save_model_path != None:\n",
    "            return join(self.args.save_model_path, self.get_task_name())\n",
    "\n",
    "        return join(self.args.out_dir, self.args.model_name, self.args.mode, self.get_task_name())\n",
    "\n",
    "    \"\"\" Gradient averaging. \"\"\"\n",
    "    def average_gradients(self, model):\n",
    "        size = float(world_size)\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.grad == None:\n",
    "                continue\n",
    "            torch.distributed.all_reduce(param.grad.data, op=torch.distributed.ReduceOp.SUM)\n",
    "            param.grad.data /= size\n",
    "\n",
    "    def get_checkpoint(self, epoch_idx, test_ppl, train_ppl):\n",
    "        ckpt_name = ''\n",
    "        if world_size == 1:\n",
    "            ckpt_name = \"epoch_{}_test_{}_train_{}.ckpt\".format(epoch_idx, test_ppl, train_ppl)\n",
    "        elif world_size > 1:\n",
    "            ckpt_name = \"epoch_{}_test_{}_train_{}_{}.ckpt\".format(epoch_idx, test_ppl, train_ppl, global_rank)\n",
    "\n",
    "        embedding = None\n",
    "        if world_size > 1:\n",
    "            embedding = self.model.model.module.state_dict()\n",
    "        else:\n",
    "            embedding = self.model.model.state_dict()\n",
    "        return {'embedding': embedding,\n",
    "                'test_ppl': test_ppl,\n",
    "                'test_size': len(self.test_set),\n",
    "                'ckpt_name': ckpt_name,\n",
    "                'time': datetime.now(),\n",
    "                'args': self.args}\n",
    "\n",
    "    def save(self, best_ckpt):\n",
    "        ckpt_name = best_ckpt['ckpt_name']\n",
    "        path = self.get_save_path()\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        torch.save(best_ckpt, join(path, ckpt_name))\n",
    "\n",
    "        log(\"# Checkpoint {} saved.\".format(ckpt_name))\n",
    "\n",
    "    def train(self):\n",
    "        test_ppl = 100000\n",
    "        best_ckpt = None\n",
    "        params=[]\n",
    "\n",
    "        if self.args.mode == 'finetune':\n",
    "            for name, param in self.model.model.named_parameters():\n",
    "                param.requires_grad = True\n",
    "            params.append({'params': self.model.model.parameters(), 'lr': self.args.lr})\n",
    "        elif self.args.mode == 'wte':\n",
    "            for name, param in self.model.model.named_parameters():\n",
    "                if 'wte' in name:\n",
    "                    param.requires_grad = True\n",
    "                    params.append({'params': param})\n",
    "        else:\n",
    "            raise NotImplementedError('wte/finetune 이외 mode는 지원하지 않습니다.')\n",
    "\n",
    "        optimizer = None\n",
    "        if self.args.optimizer == 'adam':\n",
    "            optimizer = torch.optim.Adam(params, lr=self.args.lr, weight_decay=self.args.weight_decay)\n",
    "        elif self.args.optimizer == 'adamw':\n",
    "            optimizer = AdamW(params, lr=self.args.lr, correct_bias=True)\n",
    "        else:\n",
    "            raise NotImplementedError('adam/adamw 이외 optimizer는 지원하지 않습니다.')\n",
    "\n",
    "        my_lr_scheduler = None\n",
    "\n",
    "        if self.args.scheduler == 'ExponentialLR':\n",
    "            my_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=self.args.decay_rate)\n",
    "        elif self.args.scheduler == 'TriStageLRScheduler':\n",
    "            total_steps = len(self.train_loader) * self.args.max_epochs // self.args.accumulation_steps\n",
    "            warmup_steps = 4000 // self.args.accumulation_steps\n",
    "            hold_steps = 8000 // self.args.accumulation_steps\n",
    "            my_lr_scheduler = TriStageLRScheduler(\n",
    "                optimizer,\n",
    "                init_lr=self.args.lr*1e-4,\n",
    "                peak_lr=self.args.lr,\n",
    "                final_lr=self.args.lr*1e-5,\n",
    "                init_lr_scale=0.01,\n",
    "                final_lr_scale=0.05,\n",
    "                warmup_steps=warmup_steps,\n",
    "                hold_steps=hold_steps,\n",
    "                decay_steps=total_steps-warmup_steps-hold_steps-200,\n",
    "                total_steps=total_steps,\n",
    "            )\n",
    "        elif self.args.scheduler == 'ReduceLROnPlateauScheduler':\n",
    "            my_lr_scheduler = ReduceLROnPlateauScheduler(\n",
    "                optimizer,\n",
    "                lr=self.args.lr)\n",
    "        elif self.args.scheduler == 'CosineScheduleWithWarmUp':\n",
    "            train_steps = len(self.train_loader) * self.args.max_epochs // self.args.accumulation_steps\n",
    "            warmup_steps = int(train_steps * 0.1)\n",
    "            my_lr_scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=train_steps)\n",
    "        else:\n",
    "            raise NotImplementedError('ExponentialLR/TriStageLRScheduler/ReduceLROnPlateauScheduler 이외 scheduler는 지원하지 않습니다.')\n",
    "\n",
    "        for epoch_idx in range(1, self.args.max_epochs+1):\n",
    "            total_loss=0\n",
    "            train_b_cnt=0\n",
    "\n",
    "            log(\"### START TRAIN ###\")\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            self.model.train()\n",
    "            scaler = GradScaler()\n",
    "            if world_size > 1:\n",
    "                torch.distributed.barrier()\n",
    "            for steps, batch in enumerate(tqdm(self.train_loader, bar_format='{l_bar}{bar:10}{r_bar}')):\n",
    "                if world_size > 16: # Multi-node\n",
    "                    if steps % 10 == 0:\n",
    "                        log(f'{steps}/{len(self.train_loader)} @ {datetime.now()}')\n",
    "                elif self.args.precision == 'mp': # mixed_precision\n",
    "                    with autocast():\n",
    "                        loss, _ = self.model(batch[0], batch[1])\n",
    "                        loss = loss / self.args.accumulation_steps # Gradient Accumulation 적용\n",
    "                        total_loss += loss.item()\n",
    "                    scaler.scale(loss).backward()\n",
    "                else:\n",
    "                    loss, _ = self.model(batch[0], batch[1])\n",
    "                    loss = loss / self.args.accumulation_steps # Gradient Accumulation 적용\n",
    "                    total_loss += loss.item()\n",
    "                    loss.backward()\n",
    "\n",
    "                train_b_cnt+=1\n",
    "\n",
    "                if world_size > 1:\n",
    "                    if self.args.mode == 'wte':\n",
    "                        self.average_gradients(self.model.model.module.transformer.wte)\n",
    "                    elif self.args.mode == 'finetune':\n",
    "                        self.average_gradients(self.model.model.module)\n",
    "\n",
    "                if (steps+1) % self.args.accumulation_steps == 0:\n",
    "                    if self.args.use_empty_cache == True:\n",
    "                        torch.cuda.empty_cache()\n",
    "                    if self.args.precision == 'mp': # mixed_precision\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update()\n",
    "                    else:\n",
    "                        optimizer.step()\n",
    "                    if self.args.use_empty_cache == True:\n",
    "                        torch.cuda.empty_cache()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    if self.args.scheduler == 'TriStageLRScheduler' or self.args.scheduler == 'CosineScheduleWithWarmUp':\n",
    "                        my_lr_scheduler.step()\n",
    "                    elif self.args.scheduler == 'ReduceLROnPlateauScheduler' and train_b_cnt != 0:\n",
    "                        my_lr_scheduler.step(total_loss/train_b_cnt) # Train Loss\n",
    "\n",
    "                if self.args.print_train_metric and steps%10==0:\n",
    "                    if self.args.scheduler == 'CosineScheduleWithWarmUp':\n",
    "                        log(f\"Train LR: {my_lr_scheduler.get_last_lr()[0]:.10f} Epoch {epoch_idx} Step: {steps} Loss: {total_loss/train_b_cnt:.5f} perplexity: {torch.exp(torch.tensor(total_loss/train_b_cnt)):.5f}\")\n",
    "                    else:\n",
    "                        log(f\"Train LR: {my_lr_scheduler.get_last_lr():.6f} Epoch {epoch_idx} Step: {steps} Loss: {total_loss/train_b_cnt:.5f} perplexity: {torch.exp(torch.tensor(total_loss/train_b_cnt)):.5f}\")\n",
    "\n",
    "            if self.args.scheduler == 'ExponentialLR':\n",
    "                my_lr_scheduler.step()\n",
    "\n",
    "            if train_b_cnt != 0:\n",
    "                total_loss = total_loss/train_b_cnt\n",
    "            train_ppl = torch.exp(torch.tensor(total_loss))\n",
    "\n",
    "            log(\"Train LR: {} Epoch {} Loss: {} perplexity: {}\".format(my_lr_scheduler.get_last_lr(),epoch_idx, total_loss, train_ppl))\n",
    "\n",
    "            if self.args.save_test_inference != None and global_rank == 0:\n",
    "                with open(self.args.save_test_inference, 'a') as f:\n",
    "                    wr = csv.writer(f, delimiter=\"\\t\")\n",
    "                    wr.writerow(['------------------------------', '------------------------------'])\n",
    "\n",
    "            test_ppl = None\n",
    "            if self.args.no_eval != True:\n",
    "                _, test_ppl = self.evaluate(epoch_idx)\n",
    "\n",
    "            best_ckpt = self.get_checkpoint(epoch_idx, test_ppl, train_ppl)\n",
    "            if self.args.save_model == True:\n",
    "                self.save(best_ckpt)\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "        return best_ckpt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "argument를 제공할 cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/root/eunki/baseline/train.ipynb 셀 9\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsnu_13/root/eunki/baseline/train.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatetime\u001b[39;00m \u001b[39mimport\u001b[39;00m datetime\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsnu_13/root/eunki/baseline/train.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39margparse\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bsnu_13/root/eunki/baseline/train.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mappend(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mabspath(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(\u001b[39m__file__\u001b[39;49m))))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsnu_13/root/eunki/baseline/train.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimization\u001b[39;00m \u001b[39mimport\u001b[39;00m AdamW, get_cosine_schedule_with_warmup\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsnu_13/root/eunki/baseline/train.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmisc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mevaluate_metric\u001b[39;00m \u001b[39mimport\u001b[39;00m evaluate_metric\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import csv\n",
    "import os, sys\n",
    "from os.path import join, abspath, dirname\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(__file__))))\n",
    "\n",
    "from transformers.optimization import AdamW, get_cosine_schedule_with_warmup\n",
    "from misc.evaluate_metric import evaluate_metric\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from misc.colors import Colors\n",
    "\n",
    "global_rank = int(os.getenv('RANK', '0'))\n",
    "local_rank = int(os.getenv('LOCAL_RANK', '0'))\n",
    "world_size = int(os.getenv('WORLD_SIZE', '1'))\n",
    "\n",
    "def log(string):\n",
    "    if global_rank == 0:\n",
    "        print(string, flush=True)\n",
    "\n",
    "\n",
    "def set_seed(args):\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.n_gpu > 0:\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "\n",
    "def str2bool(v):\n",
    "    if isinstance(v, bool):\n",
    "        return v\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')\n",
    "\n",
    "SUPPORT_MODELS = ['microsoft/CodeGPT-small-py', 'EleutherAI/gpt-j-6B', 'EleutherAI/gpt-neo-1.3B', 'EleutherAI/gpt-neo-125M', 'EleutherAI/gpt-neo-2.7B']\n",
    "\n",
    "global_rank = int(os.getenv('RANK', '0'))\n",
    "local_rank = int(os.getenv('LOCAL_RANK', '0'))\n",
    "world_size = int(os.getenv('WORLD_SIZE', '1'))\n",
    "\n",
    "\n",
    "def construct_generation_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # pre-parsing args\n",
    "    parser.add_argument(\"--no_cuda\", action=\"store_true\", help=\"Avoid using CUDA when available\")\n",
    "    parser.add_argument(\"--gpu_id\", type=int, default=0)\n",
    "\n",
    "    parser.add_argument(\"--use_empty_cache\", action=\"store_true\")\n",
    "\n",
    "    parser.add_argument(\"--model_name\", type=str, default='EleutherAI/gpt-neo-125M', choices=SUPPORT_MODELS)\n",
    "    parser.add_argument(\"--ckpt_pathname\", type=str, default=None)\n",
    "    parser.add_argument(\"--train_basename\", type=str, default='train')\n",
    "    parser.add_argument(\"--test_basename\", type=str, default='test')\n",
    "    parser.add_argument(\"--data_dir\", type=str, default=None)\n",
    "\n",
    "    parser.add_argument(\"--train_batch_size\", type=int, default=1)\n",
    "    parser.add_argument(\"--test_batch_size\", type=int, default=2)\n",
    "    parser.add_argument(\"--accumulation_steps\", type=int, default=4)\n",
    "    parser.add_argument(\"--max_epochs\", type=int, default=10)\n",
    "    parser.add_argument(\"--max_sequence_length\", type=int, default=2048, help='학습 입력 Sequence 길이 제한(Context+Label)') # 13B: 1024, 1.3B: 2048\n",
    "    parser.add_argument(\"--train_data_size\", type=int, default=-1) # Full\n",
    "    parser.add_argument(\"--test_data_size\", type=int, default=-1) # Full\n",
    "\n",
    "    parser.add_argument(\"--no_eval\", action=\"store_true\")\n",
    "    parser.add_argument(\"--eval_only\", action=\"store_true\")\n",
    "\n",
    "    parser.add_argument(\"--preprocess_text\", type=str2bool, default=True)\n",
    "    parser.add_argument(\"--test_original_text\", action=\"store_true\")\n",
    "\n",
    "    parser.add_argument(\"--use_summary_token\", type=str2bool, default=True)\n",
    "    parser.add_argument(\"--summary_token_type\", type=str, default='Tokens', choices=['Token', 'Tokens'])\n",
    "\n",
    "    parser.add_argument(\"--seed\", type=int, default=34, help=\"random seed for initialization\")\n",
    "    parser.add_argument(\"--lr\", type=float, default=3e-5)\n",
    "    parser.add_argument(\"--decay_rate\", type=float, default=0.9)\n",
    "    parser.add_argument(\"--weight_decay\", type=float, default=0.0005)\n",
    "\n",
    "    parser.add_argument(\"--mode\", default='finetune', choices=['finetune', 'wte'])\n",
    "\n",
    "    parser.add_argument(\"--dataset_type\", type=str, default='dacon_news',\n",
    "        choices=[\n",
    "            'humaneval',\n",
    "            'apps',\n",
    "            'codecondtest',\n",
    "        ])\n",
    "    parser.add_argument(\"--generation_max_length\", type=int, default=256)\n",
    "    parser.add_argument(\"--num_beams\", type=int, default=1)\n",
    "\n",
    "    parser.add_argument(\"--print_train_metric\", action=\"store_true\")\n",
    "    parser.add_argument(\"--save_test_inference\", type=str, default=None)\n",
    "    parser.add_argument(\"--save_model\", action=\"store_true\")\n",
    "    parser.add_argument(\"--save_model_path\", type=str, default=None)\n",
    "\n",
    "    parser.add_argument(\"--do_sample\", type=str2bool, default=False)\n",
    "    parser.add_argument(\"--precision\", type=str, default='mp', choices=['fp16', 'fp32', 'mp'])\n",
    "    parser.add_argument(\"--optimizer\", type=str, default='adamw', choices=['adam', 'adamw'])\n",
    "    parser.add_argument(\"--scheduler\", type=str, default='CosineScheduleWithWarmUp', choices=['ExponentialLR', 'TriStageLRScheduler', 'ReduceLROnPlateauScheduler', 'CosineScheduleWithWarmUp'])\n",
    "\n",
    "    parser.add_argument(\"--num_labels\", type=int, default=2)\n",
    "    parser.add_argument(\"--label_smoothing\", type=float, default=0.0)\n",
    "\n",
    "    parser.add_argument('--local_rank', type=int, default=-1, help='local rank passed from distributed launcher')\n",
    "\n",
    "    parser.add_argument('--focal_usage', type=str2bool, default=False, help='boolean for usage of focal loss')\n",
    "    parser.add_argument('--ldam_usage', type=str2bool, default=False, help='boolean for usage of focal loss')\n",
    "    parser.add_argument('--new_cb_usage', type=str2bool, default=False, help='boolean for usage of focal loss')\n",
    "    parser.add_argument('--new_cb_type', type=str, default='focal', help='Normal for Normal Focal loss, Class for Class Balanced Focal Loss')\n",
    "\n",
    "    parser.add_argument('--focal_type', type=str, default='Normal', help='Normal for Normal Focal loss, Class for Class Balanced Focal Loss')\n",
    "    parser.add_argument('--focal_gamma', type=float, default=2., help='gamma for focal loss')\n",
    "    parser.add_argument('--focal_alpha', type=float, default=0.25, help='alpha for usage of focal loss')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    log(args)\n",
    "\n",
    "    if world_size == 1:\n",
    "        os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu_id)\n",
    "        args.n_gpu = 0 if args.no_cuda else torch.cuda.device_count()\n",
    "    elif world_size > 1:\n",
    "        args.n_gpu = 0 if args.no_cuda else world_size\n",
    "\n",
    "    # post-parsing args\n",
    "    args.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # directories\n",
    "    if args.data_dir == None:\n",
    "        args.data_dir = join(abspath(dirname(__file__)), f'../data/{args.dataset_type}')\n",
    "    args.out_dir = join(abspath(dirname(__file__)), f'../out/{args.downstream_task}')\n",
    "\n",
    "    if args.downstream_task == 'summarization':\n",
    "        args.use_pad_sequence_max = True\n",
    "    args.use_pad_sequence_max = False\n",
    "\n",
    "    args.max_context_length = args.max_sequence_length - 200\n",
    "\n",
    "    assert args.accumulation_steps > 0\n",
    "    assert args.max_sequence_length >= args.max_context_length, \"Max Sequence 길이가 Max Context 길이보다 길어야 합니다!!!\"\n",
    "\n",
    "    assert not (args.mode == 'wte' and args.precision == 'fp16'), \"WTE 모드는 FP16에서 실행되지 않습니다!!!\"\n",
    "\n",
    "    set_seed(args)\n",
    "\n",
    "    return args\n",
    "\n",
    "class Trainer(object):\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        if world_size > 1:\n",
    "            self.device = f'cuda:{self.args.local_rank}'\n",
    "        elif world_size == 1:\n",
    "            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        self.model, self.tokenizer = get_gpt('EleutherAI/gpt-neo-125M')\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        if args.eval_only == True:\n",
    "            self.train_set = None\n",
    "        else:\n",
    "            self.train_set = HumanevalDatasets()\n",
    "        self.test_set = HumanevalDatasets()\n",
    "\n",
    "        os.makedirs(self.get_save_path(), exist_ok=True)\n",
    "\n",
    "        if self.args.eval_only == False:\n",
    "            self.train_loader = DataLoader(self.train_set, batch_size=self.args.train_batch_size, shuffle=True, drop_last=True)\n",
    "        elif self.args.eval_only == True:\n",
    "            self.train_loader = None\n",
    "        self.test_loader = DataLoader(self.test_set, batch_size=self.args.test_batch_size)\n",
    "\n",
    "    def evaluate(self, epoch_idx=0):\n",
    "        self.model.eval()\n",
    "\n",
    "        loader = self.test_loader\n",
    "\n",
    "        eval_b_cnt=0\n",
    "        eval_loss=0\n",
    "        with torch.no_grad():\n",
    "            log(f\"### START TEST ###\")\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            predictions = []\n",
    "            references = []\n",
    "            names = []\n",
    "            tests = []\n",
    "            entry_points = []\n",
    "            for i, (contexts, labels, name, entry_point, test) in enumerate(tqdm(loader, bar_format='{l_bar}{bar:10}{r_bar}')):\n",
    "                predictions += self.model.generate(contexts, labels)\n",
    "                references += labels\n",
    "                names += name\n",
    "                entry_points += entry_point\n",
    "                tests.append(test)\n",
    "\n",
    "                _loss,_ = self.model(contexts, labels)\n",
    "                eval_b_cnt+=1\n",
    "                eval_loss += _loss.item()\n",
    "\n",
    "            eval_loss = eval_loss/eval_b_cnt\n",
    "            perplexity = torch.exp(torch.tensor(eval_loss))\n",
    "\n",
    "            log(f\"{Colors.VIOLET}Test Epoch: {epoch_idx} Loss: {eval_loss} perplexity: {perplexity}{Colors.ENDC}\\n\")\n",
    "\n",
    "            # Metric\n",
    "            score = evaluate_metric(predictions, tests, self.args.dataset_type)\n",
    "        if self.args.save_test_inference != None and global_rank == 0:\n",
    "            with open(self.args.save_test_inference, 'a') as f:\n",
    "                wr = csv.writer(f, delimiter=\"\\t\")\n",
    "                for idx in range(len(references)):\n",
    "                    wr.writerow([epoch_idx, names[idx], references[idx], predictions[idx], score[idx]])\n",
    "\n",
    "        return eval_loss, perplexity\n",
    "\n",
    "    def get_task_name(self):\n",
    "        names = [self.args.model_name,\n",
    "                self.args.downstream_task,\n",
    "                self.args.mode,\n",
    "                self.args.dataset_type]\n",
    "        return \"_\".join(names)\n",
    "\n",
    "    def get_save_path(self):\n",
    "        if self.args.save_model_path != None:\n",
    "            return join(self.args.save_model_path, self.get_task_name())\n",
    "\n",
    "        return join(self.args.out_dir, self.args.model_name, self.args.mode, self.get_task_name())\n",
    "\n",
    "    \"\"\" Gradient averaging. \"\"\"\n",
    "    def average_gradients(self, model):\n",
    "        size = float(world_size)\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.grad == None:\n",
    "                continue\n",
    "            torch.distributed.all_reduce(param.grad.data, op=torch.distributed.ReduceOp.SUM)\n",
    "            param.grad.data /= size\n",
    "\n",
    "    def get_checkpoint(self, epoch_idx, test_ppl, train_ppl):\n",
    "        ckpt_name = ''\n",
    "        if world_size == 1:\n",
    "            ckpt_name = \"epoch_{}_test_{}_train_{}.ckpt\".format(epoch_idx, test_ppl, train_ppl)\n",
    "        elif world_size > 1:\n",
    "            ckpt_name = \"epoch_{}_test_{}_train_{}_{}.ckpt\".format(epoch_idx, test_ppl, train_ppl, global_rank)\n",
    "\n",
    "        embedding = None\n",
    "        if world_size > 1:\n",
    "            embedding = self.model.model.module.state_dict()\n",
    "        else:\n",
    "            embedding = self.model.model.state_dict()\n",
    "        return {'embedding': embedding,\n",
    "                'test_ppl': test_ppl,\n",
    "                'test_size': len(self.test_set),\n",
    "                'ckpt_name': ckpt_name,\n",
    "                'time': datetime.now(),\n",
    "                'args': self.args}\n",
    "\n",
    "    def save(self, best_ckpt):\n",
    "        ckpt_name = best_ckpt['ckpt_name']\n",
    "        path = self.get_save_path()\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        torch.save(best_ckpt, join(path, ckpt_name))\n",
    "\n",
    "        log(\"# Checkpoint {} saved.\".format(ckpt_name))\n",
    "\n",
    "    def train(self):\n",
    "        test_ppl = 100000\n",
    "        best_ckpt = None\n",
    "        params=[]\n",
    "\n",
    "        if self.args.mode == 'finetune':\n",
    "            for name, param in self.model.model.named_parameters():\n",
    "                param.requires_grad = True\n",
    "            params.append({'params': self.model.model.parameters(), 'lr': self.args.lr})\n",
    "        elif self.args.mode == 'wte':\n",
    "            for name, param in self.model.model.named_parameters():\n",
    "                if 'wte' in name:\n",
    "                    param.requires_grad = True\n",
    "                    params.append({'params': param})\n",
    "        else:\n",
    "            raise NotImplementedError('wte/finetune 이외 mode는 지원하지 않습니다.')\n",
    "\n",
    "        optimizer = None\n",
    "        if self.args.optimizer == 'adam':\n",
    "            optimizer = torch.optim.Adam(params, lr=self.args.lr, weight_decay=self.args.weight_decay)\n",
    "        elif self.args.optimizer == 'adamw':\n",
    "            optimizer = AdamW(params, lr=self.args.lr, correct_bias=True)\n",
    "        else:\n",
    "            raise NotImplementedError('adam/adamw 이외 optimizer는 지원하지 않습니다.')\n",
    "\n",
    "        my_lr_scheduler = None\n",
    "\n",
    "        if self.args.scheduler == 'ExponentialLR':\n",
    "            my_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=self.args.decay_rate)\n",
    "        elif self.args.scheduler == 'TriStageLRScheduler':\n",
    "            total_steps = len(self.train_loader) * self.args.max_epochs // self.args.accumulation_steps\n",
    "            warmup_steps = 4000 // self.args.accumulation_steps\n",
    "            hold_steps = 8000 // self.args.accumulation_steps\n",
    "            my_lr_scheduler = TriStageLRScheduler(\n",
    "                optimizer,\n",
    "                init_lr=self.args.lr*1e-4,\n",
    "                peak_lr=self.args.lr,\n",
    "                final_lr=self.args.lr*1e-5,\n",
    "                init_lr_scale=0.01,\n",
    "                final_lr_scale=0.05,\n",
    "                warmup_steps=warmup_steps,\n",
    "                hold_steps=hold_steps,\n",
    "                decay_steps=total_steps-warmup_steps-hold_steps-200,\n",
    "                total_steps=total_steps,\n",
    "            )\n",
    "        elif self.args.scheduler == 'ReduceLROnPlateauScheduler':\n",
    "            my_lr_scheduler = ReduceLROnPlateauScheduler(\n",
    "                optimizer,\n",
    "                lr=self.args.lr)\n",
    "        elif self.args.scheduler == 'CosineScheduleWithWarmUp':\n",
    "            train_steps = len(self.train_loader) * self.args.max_epochs // self.args.accumulation_steps\n",
    "            warmup_steps = int(train_steps * 0.1)\n",
    "            my_lr_scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=train_steps)\n",
    "        else:\n",
    "            raise NotImplementedError('ExponentialLR/TriStageLRScheduler/ReduceLROnPlateauScheduler 이외 scheduler는 지원하지 않습니다.')\n",
    "\n",
    "        for epoch_idx in range(1, self.args.max_epochs+1):\n",
    "            total_loss=0\n",
    "            train_b_cnt=0\n",
    "\n",
    "            log(\"### START TRAIN ###\")\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            self.model.train()\n",
    "            scaler = GradScaler()\n",
    "            if world_size > 1:\n",
    "                torch.distributed.barrier()\n",
    "            for steps, batch in enumerate(tqdm(self.train_loader, bar_format='{l_bar}{bar:10}{r_bar}')):\n",
    "                if world_size > 16: # Multi-node\n",
    "                    if steps % 10 == 0:\n",
    "                        log(f'{steps}/{len(self.train_loader)} @ {datetime.now()}')\n",
    "                elif self.args.precision == 'mp': # mixed_precision\n",
    "                    with autocast():\n",
    "                        loss, _ = self.model(batch[0], batch[1])\n",
    "                        loss = loss / self.args.accumulation_steps # Gradient Accumulation 적용\n",
    "                        total_loss += loss.item()\n",
    "                    scaler.scale(loss).backward()\n",
    "                else:\n",
    "                    loss, _ = self.model(batch[0], batch[1])\n",
    "                    loss = loss / self.args.accumulation_steps # Gradient Accumulation 적용\n",
    "                    total_loss += loss.item()\n",
    "                    loss.backward()\n",
    "\n",
    "                train_b_cnt+=1\n",
    "\n",
    "                if world_size > 1:\n",
    "                    if self.args.mode == 'wte':\n",
    "                        self.average_gradients(self.model.model.module.transformer.wte)\n",
    "                    elif self.args.mode == 'finetune':\n",
    "                        self.average_gradients(self.model.model.module)\n",
    "\n",
    "                if (steps+1) % self.args.accumulation_steps == 0:\n",
    "                    if self.args.use_empty_cache == True:\n",
    "                        torch.cuda.empty_cache()\n",
    "                    if self.args.precision == 'mp': # mixed_precision\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update()\n",
    "                    else:\n",
    "                        optimizer.step()\n",
    "                    if self.args.use_empty_cache == True:\n",
    "                        torch.cuda.empty_cache()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    if self.args.scheduler == 'TriStageLRScheduler' or self.args.scheduler == 'CosineScheduleWithWarmUp':\n",
    "                        my_lr_scheduler.step()\n",
    "                    elif self.args.scheduler == 'ReduceLROnPlateauScheduler' and train_b_cnt != 0:\n",
    "                        my_lr_scheduler.step(total_loss/train_b_cnt) # Train Loss\n",
    "\n",
    "                if self.args.print_train_metric and steps%10==0:\n",
    "                    if self.args.scheduler == 'CosineScheduleWithWarmUp':\n",
    "                        log(f\"Train LR: {my_lr_scheduler.get_last_lr()[0]:.10f} Epoch {epoch_idx} Step: {steps} Loss: {total_loss/train_b_cnt:.5f} perplexity: {torch.exp(torch.tensor(total_loss/train_b_cnt)):.5f}\")\n",
    "                    else:\n",
    "                        log(f\"Train LR: {my_lr_scheduler.get_last_lr():.6f} Epoch {epoch_idx} Step: {steps} Loss: {total_loss/train_b_cnt:.5f} perplexity: {torch.exp(torch.tensor(total_loss/train_b_cnt)):.5f}\")\n",
    "\n",
    "            if self.args.scheduler == 'ExponentialLR':\n",
    "                my_lr_scheduler.step()\n",
    "\n",
    "            if train_b_cnt != 0:\n",
    "                total_loss = total_loss/train_b_cnt\n",
    "            train_ppl = torch.exp(torch.tensor(total_loss))\n",
    "\n",
    "            log(\"Train LR: {} Epoch {} Loss: {} perplexity: {}\".format(my_lr_scheduler.get_last_lr(),epoch_idx, total_loss, train_ppl))\n",
    "\n",
    "            if self.args.save_test_inference != None and global_rank == 0:\n",
    "                with open(self.args.save_test_inference, 'a') as f:\n",
    "                    wr = csv.writer(f, delimiter=\"\\t\")\n",
    "                    wr.writerow(['------------------------------', '------------------------------'])\n",
    "\n",
    "            test_ppl = None\n",
    "            if self.args.no_eval != True:\n",
    "                _, test_ppl = self.evaluate(epoch_idx)\n",
    "\n",
    "            best_ckpt = self.get_checkpoint(epoch_idx, test_ppl, train_ppl)\n",
    "            if self.args.save_model == True:\n",
    "                self.save(best_ckpt)\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "        return best_ckpt\n",
    "\n",
    "def main():\n",
    "    args = construct_generation_args()\n",
    "\n",
    "    if args.save_test_inference != None and global_rank == 0:\n",
    "        with open(args.save_test_inference, 'w') as f:\n",
    "            wr = csv.writer(f, delimiter=\"\\t\")\n",
    "            wr.writerow(['정답', '추론'])\n",
    "\n",
    "    trainer = Trainer(args)\n",
    "\n",
    "    if args.eval_only == True:\n",
    "        trainer.evaluate()\n",
    "    else:\n",
    "        trainer.train()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "채점을 위한 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "os.environ[\"HF_ALLOW_CODE_EVAL\"] = \"1\"\n",
    "\n",
    "def evaluate_metric(predictions, entry_points, tests, dataset_type):\n",
    "    if dataset_type == 'humaneval':\n",
    "        length = len(entry_points)\n",
    "        code_eval = load('code_eval')\n",
    "        score = []\n",
    "        for i in tqdm(range(length)):\n",
    "            candidate = [[\"def \"+ entry_points[i] +'\\n' + predictions[i]] for _ in range(len(tests))]\n",
    "            pass_at_k, results = code_eval.compute(references=tests[i].strip(), predictions=candidate)\n",
    "            score.append(pass_at_k['pass@1'])\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
